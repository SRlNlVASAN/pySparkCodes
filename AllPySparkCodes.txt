[py only]

from pyspark.sql import SparkSession
spark = SparkSession.builder.appName('demo').getOrCreate()
a = [(1,'sam'),(2,'eam'),(3,'ram'),(4,'jam')]
b = ['id','name']

df = spark.createDataFrame(a,b)

df.display()
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
[sql only]

%sql
create or replace temporary view demo as
select 1 as id, 'sam' as name union
select 2 as id, 'ram' as name union
select 3 as id, 'fam' as name union
select 4 as id, 'jam' as name;

select * from demo;
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
[python and sql]

from pyspark.sql.functions import col
a = [(1,'sam'),(2,'ram'),(3,'fam')]
b = ['id','name']

df = spark.createDataFrame(a,b)

df.createOrReplaceTempView('demo')

%sql

select * from demo;
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
[read a csv]

from pyspark.sql import SparkSession
spark = SparkSession.builder.appName('demo').getOrCreate()

df = spark.read.option('header',True).option('inferSchema',True).csv('/Volumes/workspace/learningfiles/veh_data/car_prices.csv')

df.display()
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
[use withColumn for alter column and concat]

from pyspark.sql import SparkSession
spark = SparkSession.builder.appName('demo').getOrCreate()

df = spark.read.option('header','true').option('inferSchema','true').csv('/Volumes/workspace/learningfiles/veh_data/borewellVehData.csv')

df.display()

# for create new col
from pyspark.sql.functions import col,lit,concat_ws
df2 = df.withColumn('addLatLon',col('lat') + col('lon'))

df2.display()

# modify in existing col

df3 = df2.withColumn('addLatLon',col('addLatLon') - 50)

df3.display()

#concat two col in pyspark

df3 = df3.withColumn('newlatlon',concat_ws('',col('lat'),col('lon')))


df3.display()
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
[]
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
[]
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
